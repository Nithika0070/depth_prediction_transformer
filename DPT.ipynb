{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#@title Data download\n",
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"bvighnesh27/exaggerated-synthetic-corneal-data\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "id": "Ma4XgLFVoJCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Recommended minimal installs for this notebook\n",
        "!pip install -q transformers==4.40.0  # pick an LTS-compatible version\n",
        "!pip install -q datasets\n",
        "!pip install -q timm      # Optional: alternate backbones if needed"
      ],
      "metadata": {
        "id": "oQE6AdU2rX1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, glob, re, math, time, json, random\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from tqdm.auto import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "\n",
        "from transformers import AutoImageProcessor, DPTForDepthEstimation\n",
        "# AutoImageProcessor works for DPT image preprocessing"
      ],
      "metadata": {
        "id": "0znyqbiyrfuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Utility to pair images and csvs ----------\n",
        "def _numeric_key(path):\n",
        "    match = re.search(r\"\\d+\", Path(path).stem)\n",
        "    return match.group(0) if match else None\n",
        "\n",
        "def find_pairs(image_dir, csv_dir, image_exts=(\"png\",\"jpg\",\"jpeg\")):\n",
        "    images = []\n",
        "    for ext in image_exts:\n",
        "        images += glob.glob(os.path.join(image_dir, f\"**/*.{ext}\"), recursive=True)\n",
        "    csvs = glob.glob(os.path.join(csv_dir, \"**/*.csv\"), recursive=True)\n",
        "\n",
        "    csv_map = {_numeric_key(p): p for p in csvs if _numeric_key(p)}\n",
        "    print(\"CSV numeric keys found:\", csv_map.keys()) # Added for debugging\n",
        "    pairs = []\n",
        "    for img in images:\n",
        "        key = _numeric_key(img)\n",
        "        if key and key in csv_map:\n",
        "            pairs.append((img, csv_map[key]))\n",
        "        else:\n",
        "            print(f\"[WARN] No matching csv found for {img}, skipping\")\n",
        "    pairs = sorted(pairs)\n",
        "    return pairs\n",
        "\n",
        "# ---------- Dataset ----------\n",
        "class CorneaDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Returns (image_tensor, target_tensor)\n",
        "    target_tensor shape: (n_points*3,) flattened [x1,y1,z1, x2,y2,z2, ...]\n",
        "    \"\"\"\n",
        "    def __init__(self, pairs, image_processor=None, image_size=384, augment=False):\n",
        "        self.pairs = pairs\n",
        "        self.processor = image_processor\n",
        "        self.image_size = image_size\n",
        "        self.augment = augment\n",
        "        if len(self.pairs)==0:\n",
        "            raise ValueError(\"No (image,csv) pairs provided.\")\n",
        "        # determine n_points (expect consistent across CSVs)\n",
        "        self._n_points = None\n",
        "        for _, csv_path in pairs:\n",
        "            df = pd.read_csv(csv_path)\n",
        "            if df.shape[1] < 3:\n",
        "                raise ValueError(f\"CSV {csv_path} must have at least 3 columns\")\n",
        "            rows = len(df)\n",
        "            if self._n_points is None:\n",
        "                self._n_points = rows\n",
        "            elif self._n_points != rows:\n",
        "                raise ValueError(f\"Inconsistent points: {csv_path} has {rows} but expected {self._n_points}\")\n",
        "        self.target_dim = self._n_points * 3\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pairs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, csv_path = self.pairs[idx]\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        # use transformer processor if provided (keeps same logic as DPT)\n",
        "        if self.processor is not None:\n",
        "            proc = self.processor(images=image, return_tensors=\"pt\")\n",
        "            # proc contains pixel_values: shape (1, 3, H, W)\n",
        "            img_tensor = proc[\"pixel_values\"].squeeze(0)\n",
        "        else:\n",
        "            # fallback torchvision transforms\n",
        "            img_tensor = F.interpolate(torch.from_numpy(np.array(image).astype(np.float32)/255.0).permute(2,0,1).unsqueeze(0),\n",
        "                                       size=(self.image_size, self.image_size)).squeeze(0)\n",
        "\n",
        "        # read CSV target\n",
        "        df = pd.read_csv(csv_path)\n",
        "        # find columns by name or fallback to first three\n",
        "        cols = df.columns.tolist()\n",
        "        if set([\"x\",\"y\",\"z\"]).issubset(set(cols)):\n",
        "            arr = df[[\"x\",\"y\",\"z\"]].values\n",
        "        else:\n",
        "            arr = df.iloc[:, :3].values\n",
        "        target = torch.tensor(arr.reshape(-1), dtype=torch.float32)  # (n_points*3,)\n",
        "        return img_tensor, target\n",
        "\n",
        "# ---------- prepare dataloaders ----------\n",
        "def prepare_dataloaders(image_dir, csv_dir, image_processor, batch_size=8, image_size=384,\n",
        "                        train_frac=0.8, seed=42, num_workers=0):\n",
        "    pairs = find_pairs(image_dir, csv_dir)\n",
        "    if len(pairs)==0:\n",
        "        raise ValueError(\"No pairs found. Check directories.\")\n",
        "    random.Random(seed).shuffle(pairs)\n",
        "    n_train = int(len(pairs) * train_frac)\n",
        "    train_pairs = pairs[:n_train]\n",
        "    val_pairs = pairs[n_train:]\n",
        "\n",
        "    train_ds = CorneaDataset(train_pairs, image_processor=image_processor, image_size=image_size)\n",
        "    val_ds = CorneaDataset(val_pairs, image_processor=image_processor, image_size=image_size)\n",
        "\n",
        "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,\n",
        "                              num_workers=num_workers, pin_memory=True)\n",
        "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False,\n",
        "                            num_workers=num_workers, pin_memory=True)\n",
        "    info = {\n",
        "        \"n_points\": train_ds._n_points,\n",
        "        \"target_dim\": train_ds.target_dim,\n",
        "        \"n_train\": len(train_ds),\n",
        "        \"n_val\": len(val_ds),\n",
        "        \"pairs_all\": pairs\n",
        "    }\n",
        "    return train_loader, val_loader, info"
      ],
      "metadata": {
        "id": "dBWpsFWwr3_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_DIR = os.path.join(path, \"corneal_side\", \"corneal_side\")\n",
        "CSV_DIR   = os.path.join(path, \"data\", \"data\")\n",
        "# Use DPT's processor to prepare pixel values\n",
        "processor = AutoImageProcessor.from_pretrained(\"Intel/dpt-large\")\n",
        "train_loader, val_loader, info = prepare_dataloaders(IMAGE_DIR, CSV_DIR, processor, batch_size=8, image_size=384)\n",
        "print(info)"
      ],
      "metadata": {
        "id": "ntR1DQ6Msfyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7e70acb"
      },
      "source": [
        "# List the contents of the image and data directories to help identify the correct paths\n",
        "print(\"Contents of IMAGE_DIR:\")\n",
        "!ls -R \"$IMAGE_DIR\"\n",
        "\n",
        "print(\"\\nContents of CSV_DIR:\")\n",
        "!ls -R \"$CSV_DIR\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DPTRegressor(nn.Module):\n",
        "    def __init__(self, dpt_model_name=\"Intel/dpt-hybrid\", target_dim=None, pool_mode=\"avg\"):\n",
        "        \"\"\"\n",
        "        dpt_model_name: HF model checkpoint\n",
        "        target_dim: n_points * 3 (required)\n",
        "        pool_mode: 'avg' or 'flatten' (avg pooling reduces dim before MLP)\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        assert target_dim is not None, \"target_dim needed\"\n",
        "        self.dpt = DPTForDepthEstimation.from_pretrained(dpt_model_name)\n",
        "        # DPT's predicted_depth shape is (B, H, W). We'll add channel dim\n",
        "        self.pool_mode = pool_mode\n",
        "\n",
        "        # compute flattened feature dimension after pooling:\n",
        "        # if pool_mode == 'avg' -> use global avg pooled features dim = 1\n",
        "        # We'll instead use small adaptive pooling to preserve some spatial info\n",
        "        self.adaptive_pool = nn.AdaptiveAvgPool2d((16,16))  # tuneable\n",
        "        pooled_dim = 16*16  # per channel (we'll expand to 1 channel)\n",
        "\n",
        "        mlp_input_dim = pooled_dim\n",
        "        # MLP: output target_dim\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(mlp_input_dim, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(512, target_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, pixel_values):\n",
        "        \"\"\"\n",
        "        pixel_values: (B, 3, H, W) preprocessed by the AutoImageProcessor\n",
        "        returns: (B, target_dim)\n",
        "        \"\"\"\n",
        "        # Use DPT to produce predicted_depth (the usual forward)\n",
        "        # DPT returns outputs.predicted_depth shape (B, H, W)\n",
        "        outputs = self.dpt(pixel_values=pixel_values)\n",
        "        # predicted_depth shape (B, H, W) -> add channel dim\n",
        "        depth = outputs.predicted_depth.unsqueeze(1)  # (B,1,H,W)\n",
        "\n",
        "        # Adaptive pool to (B,1,16,16)\n",
        "        p = self.adaptive_pool(depth)   # (B,1,16,16)\n",
        "        x = p  # keep single channel\n",
        "        # Flatten & MLP\n",
        "        out = self.mlp(x)\n",
        "        return out"
      ],
      "metadata": {
        "id": "94NAI6esvbL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as skm\n",
        "\n",
        "def train_fit(model, train_loader, val_loader, info, device,\n",
        "              epochs=10, lr=3e-4, weight_decay=1e-2, ckpt_path=\"/content/best_vit_decoder.pth\"):\n",
        "    target_dim = info[\"target_dim\"]\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "    best_val = float(\"inf\")\n",
        "\n",
        "    history = {\"train_loss\":[], \"val_loss\":[], \"train_mae\":[], \"val_mae\":[], \"train_r2\":[], \"val_r2\":[]}\n",
        "\n",
        "    for epoch in range(1, epochs+1):\n",
        "        model.train()\n",
        "        train_losses = []\n",
        "        preds_all = []\n",
        "        trues_all = []\n",
        "        for imgs, targets in tqdm(train_loader, desc=f\"Train E{epoch}\"):\n",
        "            imgs = imgs.to(device)\n",
        "            targets = targets.to(device)  # (B, target_dim)\n",
        "            optimizer.zero_grad()\n",
        "            out = model(imgs)             # (B, target_dim)\n",
        "            loss = criterion(out, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_losses.append(loss.item())\n",
        "\n",
        "            preds_all.append(out.detach().cpu().numpy())\n",
        "            trues_all.append(targets.detach().cpu().numpy())\n",
        "\n",
        "        # aggregate train metrics\n",
        "        preds_np = np.concatenate(preds_all, axis=0)\n",
        "        trues_np = np.concatenate(trues_all, axis=0)\n",
        "        train_mse = np.mean(train_losses)\n",
        "        train_mae = skm.mean_absolute_error(trues_np, preds_np)\n",
        "        try:\n",
        "            train_r2 = skm.r2_score(trues_np, preds_np)\n",
        "        except:\n",
        "            train_r2 = float(\"nan\")\n",
        "\n",
        "        # validation\n",
        "        model.eval()\n",
        "        val_losses = []\n",
        "        preds_all = []\n",
        "        trues_all = []\n",
        "        with torch.no_grad():\n",
        "            for imgs, targets in tqdm(val_loader, desc=f\"Val E{epoch}\"):\n",
        "                imgs = imgs.to(device)\n",
        "                targets = targets.to(device)\n",
        "                out = model(imgs)\n",
        "                loss = criterion(out, targets)\n",
        "                val_losses.append(loss.item())\n",
        "                preds_all.append(out.cpu().numpy())\n",
        "                trues_all.append(targets.cpu().numpy())\n",
        "\n",
        "        preds_np = np.concatenate(preds_all, axis=0)\n",
        "        trues_np = np.concatenate(trues_all, axis=0)\n",
        "        val_mse = np.mean(val_losses)\n",
        "        val_mae = skm.mean_absolute_error(trues_np, preds_np)\n",
        "        try:\n",
        "            val_r2 = skm.r2_score(trues_np, preds_np)\n",
        "        except:\n",
        "            val_r2 = float(\"nan\")\n",
        "\n",
        "        print(f\"[Epoch {epoch}] Train MSE={train_mse:.5f} MAE={train_mae:.5f} R2={train_r2:.4f} | Val MSE={val_mse:.5f} MAE={val_mae:.5f} R2={val_r2:.4f}\")\n",
        "        history[\"train_loss\"].append(train_mse)\n",
        "        history[\"val_loss\"].append(val_mse)\n",
        "        history[\"train_mae\"].append(train_mae)\n",
        "        history[\"val_mae\"].append(val_mae)\n",
        "        history[\"train_r2\"].append(train_r2)\n",
        "        history[\"val_r2\"].append(val_r2)\n",
        "\n",
        "        scheduler.step()\n",
        "        if val_mse < best_val:\n",
        "            best_val = val_mse\n",
        "            torch.save({\n",
        "                \"epoch\": epoch,\n",
        "                \"model_state_dict\": model.state_dict(),\n",
        "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "                \"val_loss\": val_mse,\n",
        "                \"info\": info\n",
        "            }, ckpt_path)\n",
        "            print(f\"[Checkpoint] saved {ckpt_path} val_mse={val_mse:.5f}\")\n",
        "\n",
        "    return history\n"
      ],
      "metadata": {
        "id": "KIDCPPNKvzaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "target_dim = info[\"target_dim\"]\n",
        "model = DPTRegressor(dpt_model_name=\"Intel/dpt-large\", target_dim=target_dim).to(device)\n",
        "\n",
        "# Optionally freeze DPT backbone initially to train only the head:\n",
        "for p in model.dpt.parameters():\n",
        "    p.requires_grad = False\n",
        "# unfreeze head already trainable\n",
        "\n",
        "history = train_fit(model, train_loader, val_loader, info, device,\n",
        "                    epochs=10, lr=3e-4, weight_decay=1e-2, ckpt_path=\"/content/best_dpt_cornea.pth\")"
      ],
      "metadata": {
        "id": "PdDqF-DlwARb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def infer_and_save(model, dataloader, info, device, out_csv=\"/content/predictions.csv\"):\n",
        "    model.eval()\n",
        "    rows = []\n",
        "    pairs = dataloader.dataset.pairs  # (img_path, csv_path)\n",
        "    with torch.no_grad():\n",
        "        for i, (imgs, targets) in enumerate(tqdm(dataloader, desc=\"Infer\")):\n",
        "            imgs = imgs.to(device)\n",
        "            outs = model(imgs)  # (B, target_dim)\n",
        "            outs_np = outs.cpu().numpy()\n",
        "            targets_np = targets.numpy()\n",
        "            batch_size = outs_np.shape[0]\n",
        "            for b in range(batch_size):\n",
        "                img_path, csv_path = pairs[i * dataloader.batch_size + b]\n",
        "                # reshape predicted values back to Nx3 for convenience\n",
        "                n_points = info[\"n_points\"]\n",
        "                pred_flat = outs_np[b]\n",
        "                pred_points = pred_flat.reshape(n_points, 3)\n",
        "                # flatten to a string or store columns\n",
        "                row = {\n",
        "                    \"image\": os.path.basename(img_path),\n",
        "                    \"csv\": os.path.basename(csv_path),\n",
        "                    \"pred_flat\": json.dumps(pred_flat.tolist())\n",
        "                }\n",
        "                rows.append(row)\n",
        "    df = pd.DataFrame(rows)\n",
        "    df.to_csv(out_csv, index=False)\n",
        "    print(\"Saved predictions to\", out_csv)\n",
        "\n",
        "# Example usage:\n",
        "model_ckpt = torch.load(\"/content/best_dpt_cornea.pth\", map_location=device, weights_only=False)\n",
        "model.load_state_dict(model_ckpt[\"model_state_dict\"])\n",
        "infer_and_save(model, val_loader, info, device=device, out_csv=\"/content/predictions_val.csv\")"
      ],
      "metadata": {
        "id": "427gqexE3vh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "def plot_gt_vs_pred(image_path, gt_csv, pred_flat):\n",
        "    # load image\n",
        "    img = Image.open(image_path).convert(\"RGB\")\n",
        "    gt = pd.read_csv(gt_csv)\n",
        "    # get points Nx3\n",
        "    if set([\"x\",\"y\",\"z\"]).issubset(set(gt.columns)):\n",
        "        gt_points = gt[[\"x\",\"y\",\"z\"]].values\n",
        "    else:\n",
        "        gt_points = gt.iloc[:,:3].values\n",
        "    pred_points = np.array(pred_flat).reshape(-1,3)\n",
        "\n",
        "    fig = plt.figure(figsize=(12,5))\n",
        "    ax0 = fig.add_subplot(121)\n",
        "    ax0.imshow(img); ax0.axis(\"off\"); ax0.set_title(\"Image\")\n",
        "    ax1 = fig.add_subplot(122, projection='3d')\n",
        "    ax1.scatter(gt_points[:,0], gt_points[:,1], gt_points[:,2], s=2, c='blue', label='GT')\n",
        "    ax1.scatter(pred_points[:,0], pred_points[:,1], pred_points[:,2], s=2, c='red', label='Pred')\n",
        "    ax1.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Example: pick first val sample\n",
        "img_path, csv_path = val_loader.dataset.pairs[0]\n",
        "# load pred from saved csv or infer on the fly:\n",
        "with torch.no_grad():\n",
        "    img_tensor, target = val_loader.dataset[0]\n",
        "    pred_flat = model(img_tensor.unsqueeze(0).to(device)).cpu().numpy().squeeze()\n",
        "plot_gt_vs_pred(img_path, csv_path, pred_flat)\n"
      ],
      "metadata": {
        "id": "pyGnwzGH6IZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(history[\"train_loss\"], label=\"Train Loss\", marker='o')\n",
        "plt.plot(history[\"val_loss\"], label=\"Validation Loss\", marker='o')\n",
        "plt.title(\"Training vs Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"MSE Loss\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "uUU-chKI2HQc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}